# LLMフレンドリーなサーバーレスポンスの改善

## 概要

MCPサーバーからの出力がLLMフレンドリーではないため、LLMがコードチャンクを解析してユーザーに有用なレスポンスを返すことが難しくなっています。ユーザー・Agent・LLM・MCPサーバー間で適切な会話が行えるよう、MCPサーバーからのレスポンスに自然言語による補足を追加する必要があります。

## 詳細

### 優先度

高

### 問題点

- MCPサーバーの各ツールのレスポンスは、主に構造化されたデータ（JSONやコード片）のみを返しており、LLMが次の手順を判断するための自然言語による補足が不足しています。
- これにより、LLMがサーバーからの情報を適切に解釈し、ユーザーへの有用な応答や次のアクションを生成することが困難になっています。

### 解決方法

- [ ] MCPサーバーの各ツールのレスポンスに、LLMが理解しやすい自然言語の補足を追加します。具体的には、以下の要素をJSON形式でレスポンスの `content.text` フィールドに埋め込むことを検討します。
  - `description`: レスポンスが何を意味するのか、なぜ返されたのか、そしてLLMに何をしてほしいのかを説明する自然言語の要約。
  - `suggested_actions`: LLMが次に実行を検討すべきアクションのリスト。
  - `follow_up_questions`: LLMがユーザーに尋ねるべき質問のリスト。
- [ ] 各ツールのレスポンス例を更新し、新しい形式を反映させます。

### 影響を受けるツール

- `analyze_project`
- `get_chunk` / `get_function_chunk` / `get_entity_chunk`
- `list_functions_in_file` / `list_entities_in_file`
- `find_file` / `find_function`

## その他

ロードマップの「フェーズ3: 高度なコード理解機能」の一部として対応を検討します。
